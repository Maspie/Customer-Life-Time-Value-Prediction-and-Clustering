{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maspie/Customer-Life-Time-Value-Prediction-and-Clustering/blob/main/Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPxZ-TwpBrQF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2V12J7H8x9V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhr30LGQCExP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5qcwuLf9JMF"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# df = pd.read_csv('/content/drive/My Drive/Clustered Dataset/cleaned_cltv.csv')\n",
        "\n",
        "url = \"https://drive.google.com/uc?export=download&id=176F7rnRdMAW9OPIDrdDpXiQfnUZ3TXv0\"\n",
        "dataset_cluster = pd.read_csv(url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IeEZLUAVeiB"
      },
      "source": [
        "Previewing the dataset before dropping features in the main EDA notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gwn3t4aOSMaA"
      },
      "outputs": [],
      "source": [
        "dataset_cluster.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQAVjU5OVpCL"
      },
      "source": [
        "Applying Minibatch Kmeans since size of dataset is big and finding number of clustering through elbow method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SXRS4fY01dq"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import numpy as np\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "dataset_cluster['cltv'] = scaler.fit_transform(dataset_cluster[['cltv']])\n",
        "dataset_cluster['claim_amount'] = scaler.fit_transform(dataset_cluster[['claim_amount']])\n",
        "dataa = dataset_cluster.copy()\n",
        "# Determine the optimal number of clusters using the elbow method\n",
        "sse = []\n",
        "k_candidates = range(1, 15)\n",
        "\n",
        "for k in k_candidates:\n",
        "    kmeans = MiniBatchKMeans(n_clusters=k, batch_size=100, random_state=42)\n",
        "    kmeans.fit(dataset_cluster)\n",
        "    sse.append(kmeans.inertia_)\n",
        "\n",
        "# Plot SSE (elbow method)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_candidates, sse, '-o')\n",
        "plt.xlabel('Number of clusters, k')\n",
        "plt.ylabel('Sum of squared distances')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehr16sYHDETC"
      },
      "outputs": [],
      "source": [
        "dataa.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qARIQXfAWB-S"
      },
      "source": [
        "Mini Batch Kmeans, SSE and Davies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqkN-NUWn_Ba"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "\n",
        "n_clusters = 3\n",
        "batch_size = 1000\n",
        "\n",
        "kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, random_state=100)\n",
        "\n",
        "kmeans.fit(dataset_cluster)\n",
        "\n",
        "centers_kmeans = kmeans.cluster_centers_\n",
        "labels_kmeans = kmeans.labels_\n",
        "\n",
        "if not isinstance(dataset_cluster, pd.DataFrame):\n",
        "    df_kmeans = pd.DataFrame(dataset_cluster)\n",
        "else:\n",
        "    df_kmeans = dataset_cluster.copy()\n",
        "\n",
        "df_kmeans['Cluster'] = labels_kmeans\n",
        "\n",
        "# Calculate SSE for each cluster\n",
        "sse_per_cluster = np.zeros(n_clusters)\n",
        "for i in range(n_clusters):\n",
        "    cluster_points = df_kmeans[df_kmeans['Cluster'] == i].drop('Cluster', axis=1)\n",
        "    distances = np.linalg.norm(cluster_points - centers_kmeans[i], axis=1)\n",
        "    sse_per_cluster[i] = np.mean(np.square(distances))\n",
        "\n",
        "# Mean SSE across all clusters\n",
        "mean_sse = np.mean(sse_per_cluster)\n",
        "\n",
        "print(f\"Mean SSE per cluster: {sse_per_cluster}\")\n",
        "print(f\"Mean SSE across all clusters: {mean_sse}\")\n",
        "\n",
        "db_score_kmeans = davies_bouldin_score(df_kmeans.drop('Cluster', axis=1), labels_kmeans)\n",
        "print(f\"Davies-Bouldin Index: {db_score_kmeans}\")\n",
        "\n",
        "sse_kmeans = kmeans.inertia_\n",
        "print(f\"Sum of Squared Error (Total Inertia): {sse_kmeans/1017209}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-Y3Qw-CXuvn"
      },
      "source": [
        "\n",
        "BIRCH , SSE and Davies Score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZBAd0Nqy2PT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import Birch\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "\n",
        "# dataa = pd.DataFrame(np.random.rand(100, 2))\n",
        "\n",
        "if isinstance(dataa, pd.DataFrame):\n",
        "    dataa = dataa.values\n",
        "\n",
        "# Setting up the BIRCH clustering\n",
        "birch = Birch(n_clusters=3, threshold=0.6, branching_factor=20)\n",
        "labels_birch = birch.fit_predict(dataa)\n",
        "\n",
        "# Compute the centroids of each cluster\n",
        "centroids_birch = np.array([dataa[labels_birch == i].mean(axis=0) for i in range(3)])\n",
        "\n",
        "sse_per_cluster = np.zeros(3)\n",
        "\n",
        "# Calculate the SSE for each cluster\n",
        "for i in range(3):\n",
        "    cluster_points = dataa[labels_birch == i]\n",
        "    cluster_center = centroids_birch[i]\n",
        "    sse = np.sum((cluster_points - cluster_center) ** 2)\n",
        "    sse_per_cluster[i] = sse\n",
        "\n",
        "# Calculate mean SSE by dividing by the number of points in each cluster\n",
        "num_points_per_cluster = np.array([sum(labels_birch == i) for i in range(3)])\n",
        "mean_sse_per_cluster = sse_per_cluster / num_points_per_cluster\n",
        "\n",
        "# Print the mean SSE for each cluster\n",
        "for i, mean_sse in enumerate(mean_sse_per_cluster):\n",
        "    print(f\"Mean SSE for Cluster {i}: {mean_sse}\")\n",
        "\n",
        "# Calculate and print the overall SSE divided by total data points\n",
        "total_sse = np.sum(sse_per_cluster)\n",
        "print(f\"Overall Mean SSE (divided by total data points): {total_sse / len(dataa)}\")\n",
        "\n",
        "# Calculate and print the Davies-Bouldin Score\n",
        "db_score = davies_bouldin_score(dataa, labels_birch)\n",
        "print(f\"Davies-Bouldin Index: {db_score}\")\n",
        "\n",
        "# Mean SSE across all clusters divided by the total number of data points\n",
        "mean_sse_across_clusters = total_sse / len(dataa)\n",
        "print(f\"Mean SSE across all clusters (divided by total data points): {mean_sse_across_clusters}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPiz1aUWL36e"
      },
      "outputs": [],
      "source": [
        "print(sse_per_cluster/len(dataa))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgRFBPjNX5Yo"
      },
      "source": [
        "2D RERESENTATION, PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzMg1z8DR84i"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Apply PCA to reduce dimensions to 2 for visualization\n",
        "pca = PCA(n_components=2)\n",
        "dataa_pca = pca.fit_transform(dataset_cluster)\n",
        "\n",
        "# Sample 100 points from each cluster\n",
        "samples_per_cluster = 100\n",
        "colors = ['red', 'blue', 'green']  # Colors for clusters 0, 1, 2\n",
        "\n",
        "def sample_data(labels):\n",
        "    sampled_indices = np.hstack([np.random.choice(np.where(labels == i)[0], samples_per_cluster, replace=False) for i in range(3)])\n",
        "    return dataa_pca[sampled_indices], labels[sampled_indices]\n",
        "\n",
        "# Sample data for Birch and KMeans\n",
        "dataa_pca_birch, labels_birch_sampled = sample_data(labels_birch)\n",
        "dataa_pca_kmeans, labels_kmeans_sampled = sample_data(labels_kmeans)\n",
        "\n",
        "# Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "# Plotting function for 2D\n",
        "def plot_clusters(ax, data, labels, centroids, title, score_text):\n",
        "    for i, color in enumerate(colors):\n",
        "        cluster_data = data[labels == i]\n",
        "\n",
        "        ax.scatter(cluster_data[:, 0], cluster_data[:, 1], c=color, label=f'Cluster {i}', alpha=0.5)\n",
        "\n",
        "\n",
        "        centroid = centroids[i]\n",
        "        ax.scatter(centroid[0], centroid[1], marker='x', s=100, color='k')\n",
        "\n",
        "        # lines from samples to the centroid\n",
        "        for point in cluster_data:\n",
        "            ax.plot([point[0], centroid[0]], [point[1], centroid[1]], 'k--', linewidth=0.5, alpha=0.3)\n",
        "\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('PCA Component 1')\n",
        "    ax.set_ylabel('PCA Component 2')\n",
        "    plt.legend(loc='upper right')\n",
        "    ax.text(0.05, -0.1, score_text, transform=ax.transAxes)\n",
        "\n",
        "# Calculate centroids for the samples in 2D\n",
        "centroids_birch_pca = np.array([dataa_pca_birch[labels_birch_sampled == i].mean(axis=0) for i in range(3)])\n",
        "centroids_kmeans_pca = np.array([dataa_pca_kmeans[labels_kmeans_sampled == i].mean(axis=0) for i in range(3)])\n",
        "\n",
        "# Plot for Birch\n",
        "plot_clusters(ax1, dataa_pca_birch, labels_birch_sampled, centroids_birch_pca, 'Birch Clustering', 'SSE: {:.2f}\\nDavies-Bouldin Index: {:.2f}'.format(total_sse, db_score))\n",
        "\n",
        "# Plot for KMeans\n",
        "plot_clusters(ax2, dataa_pca_kmeans, labels_kmeans_sampled, centroids_kmeans_pca, 'KMeans Clustering', 'SSE: {:.2f}\\nDavies-Bouldin Index: {:.2f}'.format(sse_kmeans, db_score_kmeans))\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqpdWlFwYP1b"
      },
      "source": [
        "3D RERESENTATION, PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZIyYMC8DJoZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Taking 100 samples per cluster\n",
        "samples_per_cluster = 100\n",
        "colors = ['red', 'blue', 'green']\n",
        "\n",
        "# Sample indices for each cluster\n",
        "def sample_indices(labels, n_samples_per_cluster):\n",
        "    unique_labels = np.unique(labels)\n",
        "    indices = np.hstack([np.random.choice(np.where(labels == label)[0], n_samples_per_cluster, replace=False)\n",
        "                         for label in unique_labels])\n",
        "    return indices\n",
        "\n",
        "# Sample indices from the original labels\n",
        "birch_indices = sample_indices(labels_birch, samples_per_cluster)\n",
        "kmeans_indices = sample_indices(labels_kmeans, samples_per_cluster)\n",
        "\n",
        "# Applying PCA to reduce dimensions to 3 for visualization\n",
        "pca = PCA(n_components=3)\n",
        "\n",
        "# Dataframe check\n",
        "if isinstance(dataset_cluster, pd.DataFrame):\n",
        "    dataa_pca_3d_birch = pca.fit_transform(dataset_cluster.iloc[birch_indices].values)\n",
        "    dataa_pca_3d_kmeans = pca.transform(dataset_cluster.iloc[kmeans_indices].values)\n",
        "else:\n",
        "    dataa_pca_3d_birch = pca.fit_transform(dataset_cluster[birch_indices])\n",
        "    dataa_pca_3d_kmeans = pca.transform(dataset_cluster[kmeans_indices])\n",
        "\n",
        "# Labels update\n",
        "labels_birch_sampled = labels_birch[birch_indices]\n",
        "labels_kmeans_sampled = labels_kmeans[kmeans_indices]\n",
        "\n",
        "# Centroid calculation\n",
        "centroids_birch = np.array([dataa_pca_3d_birch[labels_birch_sampled == i].mean(axis=0) for i in np.unique(labels_birch_sampled)])\n",
        "centroids_kmeans = np.array([dataa_pca_3d_kmeans[labels_kmeans_sampled == i].mean(axis=0) for i in np.unique(labels_kmeans_sampled)])\n",
        "\n",
        "# Visualization in 3D\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "ax1 = fig.add_subplot(121, projection='3d', title='Birch Clustering 3D')\n",
        "ax2 = fig.add_subplot(122, projection='3d', title='KMeans Clustering 3D')\n",
        "\n",
        "# plot clusters and centroid lines in 3D\n",
        "def plot_clusters_3d(ax, data, labels, centroids, title):\n",
        "    for i, color in enumerate(colors):\n",
        "\n",
        "        cluster_data = data[labels == i]\n",
        "\n",
        "        ax.scatter(cluster_data[:, 0], cluster_data[:, 1], cluster_data[:, 2], c=color, label=f'Cluster {i}', alpha=0.5)\n",
        "\n",
        "        ax.scatter(centroids[i][0], centroids[i][1], centroids[i][2], c='k', marker='x', s=100)\n",
        "\n",
        "        # lines from each point to the centroid\n",
        "        for point in cluster_data:\n",
        "            ax.plot([point[0], centroids[i][0]], [point[1], centroids[i][1]], [point[2], centroids[i][2]], 'k-', linewidth=0.5, alpha=0.5)\n",
        "\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('PCA Component 1')\n",
        "    ax.set_ylabel('PCA Component 2')\n",
        "    ax.set_zlabel('PCA Component 3')\n",
        "    ax.legend()\n",
        "\n",
        "# Plot for Birch in 3D\n",
        "plot_clusters_3d(ax1, dataa_pca_3d_birch, labels_birch_sampled, centroids_birch, 'Birch Clustering 3D')\n",
        "\n",
        "# Plot for KMeans in 3D\n",
        "plot_clusters_3d(ax2, dataa_pca_3d_kmeans, labels_kmeans_sampled, centroids_kmeans, 'KMeans Clustering 3D')\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpKzmrz2hbcJX/4d5FtQWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
