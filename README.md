

# Unlocking Future Value: Optimizing Insurance Offerings with CLTV Prediction and Customer Segmentation

## Project Overview
This project focuses on developing a predictive model to estimate Customer Lifetime Value (CLTV). By utilizing machine learning techniques such as Gradient Boosting and clustering algorithms like Mini Batch K-Means and BIRCH, the model aims to enhance personalized insurance policies and optimize resource allocation. This initiative seeks to improve customer segmentation, marketing strategies, and overall customer satisfaction, driving data-driven, customer-centric practices in the insurance industry.

## Hereâ€™s how it works:

Data Collection: Gather comprehensive customer data from various sources.

Data Preprocessing: Clean and prepare data by encoding variables, normalizing columns, and reducing multicollinearity.

Exploratory Data Analysis (EDA): Identify trends and patterns using distribution analysis, correlation matrices, and visualizations.

Model Training and Selection: Train and select the most accurate machine learning model to predict Customer Lifetime Value (CLTV).

Hyperparameter Tuning: Optimize model performance with hyperparameter tuning and cross-validation.

Customer Segmentation: Use clustering algorithms to segment customers based on predicted CLTV.

Application of Insights: Personalize insurance policies and improve resource allocation and customer satisfaction with tailored strategies.


![Data Pipeline](Tweets_Preprocessing/Diag.png)







## Screenshots

#### Initial Clusters

![Initial Clusters](Tweets_Preprocessing/Cluster1.png)

#### Sub-Clusters level 1
![Sub Clusters lvl. 1](Tweets_Preprocessing/Cluster2.png)














## Methodology

Data Pipeline

![Result](Tweets_Preprocessing/flow.png)

## Results

![Result](Tweets_Preprocessing/ss.jpeg)

## Technologies used

- Python: The primary programming language used for developing the project.

- Scikit-Learn: Utilized for implementing machine learning algorithms for clustering.

- NLTK: Used for natural language processing tasks such as tokenization and stopwords removal.

- OpenAI API: Integrates advanced AI models for generating text summaries.

- Pandas & NumPy: Handle data manipulation and mathematical operations.

- LangChain: Incorporated to leverage its capabilities in chaining language models for complex workflows, enhancing the automation of generating coherent and contextually appropriate text outputs.
## Conclusion

This project outlines strategy to improve content discovery on platforms like Twitter and Reddit using Natural Language Processing (NLP) and Machine Learning (ML). Our method involved collecting and processing data to form semantic-rich text clusters, which help users find relevant and interesting content. We enhanced discovery with a ranking algorithm to highlight the most pertinent tweets and employed Retrieval Augmented Generation (RAG) for generating summaries and recommendations.

Results show that this approach effectively organizes content according to user interests and enhances engagement by providing clearer insights into community themes. This project ultimately aims to enrich user interactions and foster more vibrant online communities.
## Possible Future Works

- Using different clustering techniques.
- Improving RAG and whole model

